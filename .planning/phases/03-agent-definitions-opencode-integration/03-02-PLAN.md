---
phase: 03-agent-definitions-opencode-integration
plan: 02
type: execute
wave: 2
depends_on: ["03-01"]
files_modified:
  - src/data_architect/templates.py
  - tests/test_scaffold.py
  - tests/test_cli.py
autonomous: true

must_haves:
  truths:
    - "After architect init, .opencode/skills/ contains 4 skill directories (da-start, da-review, da-status, da-export), each with a SKILL.md"
    - "All skills route through Data Architect agent as single orchestration point -- no skill directly invokes subagents"
    - "/da:export skill writes specs to .data-architect/specs/ (fixed, predictable location)"
    - "All existing scaffold and CLI tests pass with updated file counts"
    - "Agent content tests verify real prompts exist (no TODO stubs remain)"
  artifacts:
    - path: "src/data_architect/templates.py"
      provides: "Complete TEMPLATES dict with all scaffolded files (agents, skills, AGENTS.md, opencode.json, spec schemas)"
      contains: "da-review"
    - path: "tests/test_scaffold.py"
      provides: "Updated scaffold tests with correct file count and content assertions"
      contains: "test_manifest_has_expected_file_count"
    - path: "tests/test_cli.py"
      provides: "Updated CLI tests with correct file count assertions"
      contains: "test_init_creates_all"
  key_links:
    - from: "skill SKILL.md content"
      to: "data-architect agent"
      via: "agent: data-architect in skill frontmatter"
      pattern: "agent: data-architect"
    - from: "tests/test_scaffold.py"
      to: "src/data_architect/templates.py"
      via: "TEMPLATES import and count assertion"
      pattern: "len\\(TEMPLATES\\)"
    - from: "tests/test_cli.py"
      to: "src/data_architect/templates.py"
      via: "TEMPLATES import and file count in output assertions"
      pattern: "\\d+ created"
---

<objective>
Add all four skill definitions (/da:start, /da:review, /da:status, /da:export) to the TEMPLATES dict and update all tests to reflect the final file manifest.

Purpose: Skills are the user's entry point to the agent team -- they invoke `/da:start` to begin modeling, `/da:review` to check a spec, `/da:status` to see progress, and `/da:export` to write specs. Without skills, agents are defined but unreachable. Tests must validate the complete manifest to prevent regressions.

Output: Updated `templates.py` with 4 skill entries, updated `test_scaffold.py` and `test_cli.py` with correct file counts and new content assertions.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-agent-definitions-opencode-integration/03-CONTEXT.md
@.planning/phases/03-agent-definitions-opencode-integration/03-RESEARCH.md
@.planning/phases/03-agent-definitions-opencode-integration/03-01-SUMMARY.md
@src/data_architect/templates.py
@src/data_architect/scaffold.py
@tests/test_scaffold.py
@tests/test_cli.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add skill definitions to TEMPLATES</name>
  <files>src/data_architect/templates.py</files>
  <action>
Add 3 new skill entries to TEMPLATES and replace the existing da-start stub with real content. After this task, TEMPLATES should have 4 skill entries total.

**YAML frontmatter for ALL skills** (per research Pattern 2):
- `name`: skill name (e.g., `da-start`)
- `description`: One-line description
- `disable-model-invocation: true` (skills don't pick models)
- `context: fork` (each skill invocation gets fresh context)
- `agent: data-architect` (ALL skills route through Data Architect per locked decision)

**Skill 1: /da:start** (replace existing stub at `.opencode/skills/da-start/SKILL.md`):
- H1: "Start Data Warehouse Design Session"
- Instructions for Data Architect to:
  1. Greet the user and confirm the domain from `$ARGUMENTS`
  2. If this is the first interaction, ask user to choose model tier (budget/standard/high) and explain what each means
  3. Explain the CLP process at a high level (Conceptual -> Logical -> Physical)
  4. Ask initial discovery questions: What business questions need answering? What source systems exist? What are the key business entities? Where are source docs in the filesystem?
  5. Document initial responses in session context
  6. Begin discovery with domain requirements gathering and source system analysis
- Include note: "Route all orchestration through your own context -- you are the single entry point."
- IMPORTANT: Do NOT mention specific subagents (@business-analyst, @system-analyst, etc.) in the skill instructions. The skill tells the Data Architect WHAT to accomplish (domain requirements, source analysis), not HOW to accomplish it (which agents to delegate to). The Data Architect decides orchestration per locked decision: "All skills route through Data Architect as single orchestration point."

**Skill 2: /da:review** (new entry at `.opencode/skills/da-review/SKILL.md`):
- H1: "Review Anchor Model Spec"
- Instructions for Data Architect to:
  1. Load and parse the spec file from `$ARGUMENTS` (or find latest in `.data-architect/specs/`)
  2. Validate naming conventions against AGENTS.md rules
  3. Check structural completeness: Do all anchors have attributes? Are tie directions correct? Are knots appropriate?
  4. Perform anti-pattern detection and critique
  5. Summarize findings in structured format: Naming Issues, Structural Issues, Anti-Patterns, Recommendations
- Include note: "You orchestrate the review -- synthesize all critique into actionable findings."

**Skill 3: /da:status** (new entry at `.opencode/skills/da-status/SKILL.md`):
- H1: "Check Design Session Status"
- Instructions for Data Architect to:
  1. Report current CLP stage (Conceptual, Logical, or Physical)
  2. List entities identified so far (anchors, ties, knots)
  3. Summarize open questions and unresolved debates
  4. List next steps
  5. If no active session, tell the user to start one with `/da:start`
- This is an informational skill -- reads state, does not modify

**Skill 4: /da:export** (new entry at `.opencode/skills/da-export/SKILL.md`):
- H1: "Export Spec to YAML"
- Instructions for Data Architect to:
  1. Gather the current model state from session context
  2. Validate completeness: Are there unresolved debates? Missing attributes? Incomplete ties?
  3. If incomplete, warn user and list what's missing
  4. If complete (or user confirms partial export), write YAML spec to `.data-architect/specs/` (fixed location per locked decision)
  5. Use naming convention: `.data-architect/specs/<domain>-spec.yaml` where domain comes from the session
  6. Confirm export path and show summary of what was exported
- Include note: "Specs are written to `.data-architect/specs/` -- this location is fixed and predictable."

**Constraints:**
- All skills set `agent: data-architect` in frontmatter (locked decision)
- No skill mentions @business-analyst, @system-analyst, @veteran-reviewer, or any other subagent by @name in its instructions. Skills describe WHAT the Data Architect should accomplish, not which agents to delegate to. The Data Architect's own prompt (in 03-01) defines its team orchestration knowledge.
- Keep skill instructions concise: 20-50 lines each
  </action>
  <verify>
Run `python -c "from data_architect.templates import TEMPLATES; skills = [k for k in TEMPLATES if '/skills/' in k]; print(f'{len(skills)} skills'); [print(k) for k in skills]"` to confirm 4 skill entries exist. Then verify all skill content contains `agent: data-architect` in frontmatter. Then verify no skill body contains `@business-analyst`, `@system-analyst`, `@veteran-reviewer`, `@data-engineer`, or `@analytics-engineer`: `python -c "from data_architect.templates import TEMPLATES; [print('FAIL:', k) for k in TEMPLATES if '/skills/' in k for name in ['@business-analyst','@system-analyst','@veteran-reviewer','@data-engineer','@analytics-engineer'] if name in TEMPLATES[k]]"` should produce no output.
  </verify>
  <done>
TEMPLATES has 4 skill entries: da-start, da-review, da-status, da-export. All skills have `agent: data-architect` in YAML frontmatter. No skill directly references any subagent by @name. /da:export references `.data-architect/specs/` as export location.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update all tests for final file manifest</name>
  <files>tests/test_scaffold.py, tests/test_cli.py</files>
  <action>
Update all test assertions to reflect the final TEMPLATES count and content.

**Determine final file count from TEMPLATES after Task 1:**
Count all keys in TEMPLATES. Expected entries (14 total):
- 6 agent files (.opencode/agents/*.md)
- 4 skill files (.opencode/skills/da-*/SKILL.md)
- 1 AGENTS.md
- 1 opencode.json
- 2 spec schema files (.data-architect/specs/examples/*.yaml)

**test_scaffold.py updates:**

1. `test_manifest_has_expected_file_count`: Change `assert len(TEMPLATES) == 9` to `assert len(TEMPLATES) == 14`

2. `test_scaffold_creates_subdirectories`: Add assertions for new directories:
   - `assert (tmp_path / ".opencode" / "skills" / "da-review").is_dir()`
   - `assert (tmp_path / ".opencode" / "skills" / "da-status").is_dir()`
   - `assert (tmp_path / ".opencode" / "skills" / "da-export").is_dir()`
   - `assert (tmp_path / ".data-architect" / "specs" / "examples").is_dir()`

3. Add new test `test_all_skill_files_have_yaml_frontmatter`:
   - Filter TEMPLATES for paths containing `/skills/`
   - Assert 4 skill files found
   - Assert each starts with `---` (YAML frontmatter)

4. Add new test `test_agents_have_no_model_field`:
   - Filter TEMPLATES for agent files
   - For each agent, extract content between first `---` and second `---` (frontmatter)
   - Assert `model:` does NOT appear in any agent's frontmatter

5. Add new test `test_agents_have_cross_references`:
   - Filter TEMPLATES for agent files
   - Assert each agent body (after frontmatter) contains at least one `@` mention of another agent (e.g., `@data-architect` or `@business-analyst`)

6. Add new test `test_agents_md_has_naming_conventions`:
   - Get AGENTS.md content from TEMPLATES
   - Assert it contains `anchor__` (naming convention examples)
   - Assert it contains `tie__` (naming convention examples)
   - Assert it contains `knot__` (naming convention examples)

7. Add new test `test_no_todo_stubs_remain`:
   - Iterate ALL TEMPLATES values
   - Assert no template contains `<!-- TODO:` (Phase 2 stubs are all gone)

**test_cli.py updates:**

1. `test_init_creates_all_nine_files`: Rename to `test_init_creates_all_files`. Change `assert len(created_files) == 9` to `assert len(created_files) == 14`

2. `test_init_prints_summary`: Change `assert "9 created"` to `assert "14 created"`

3. `test_init_skips_summary_line`: Change `assert "9 skipped"` to `assert "14 skipped"`

4. `test_init_dry_run_file_count`: Change `assert "9 files would be created"` to `assert "14 files would be created"`

5. All other tests should pass without changes since they use `TEMPLATES` dynamically.

**Constraints:**
- Use the actual len(TEMPLATES) at test time where possible, but explicit count assertions (like `== 14`) are intentional regression guards
- Keep test names descriptive and follow existing naming pattern
- Import TEMPLATES in test files (already imported)
  </action>
  <verify>
Run `make check` -- all lint, type, and test must pass with zero failures. Then run `python -m pytest tests/ -v --tb=short` to see all test names and confirm new tests appear.
  </verify>
  <done>
All existing tests updated with correct file counts (14). New tests added: skill frontmatter validation, no-model-in-agents, cross-references, naming conventions in AGENTS.md, no-TODO-stubs. `make check` passes with zero failures. `pytest -v` shows all new test names.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from data_architect.templates import TEMPLATES; print(len(TEMPLATES))"` outputs 14
2. All 4 skill files have `agent: data-architect` in YAML frontmatter
3. No skill SKILL.md references any subagent by @name -- skills describe WHAT, not which agents
4. /da:export skill references `.data-architect/specs/` as output location
5. `make check` passes -- zero lint warnings, zero type errors, zero test failures
6. `python -m pytest tests/ -v` shows all new tests passing
7. No `<!-- TODO:` stubs remain in any TEMPLATES value
</verification>

<success_criteria>
- TEMPLATES has exactly 14 entries: 6 agents, 4 skills, AGENTS.md, opencode.json, 2 spec schemas
- All 4 skills route through Data Architect (agent: data-architect)
- No skill references subagents by @name -- Data Architect decides orchestration
- /da:export writes to .data-architect/specs/ (fixed location)
- All scaffold tests pass with file count 14
- All CLI tests pass with file count 14
- New content-validation tests pass (no stubs, frontmatter valid, cross-references exist)
- `make check` green
</success_criteria>

<output>
After completion, create `.planning/phases/03-agent-definitions-opencode-integration/03-02-SUMMARY.md`
</output>

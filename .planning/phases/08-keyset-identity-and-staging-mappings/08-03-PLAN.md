---
phase: 08-keyset-identity-and-staging-mappings
plan: 03
type: execute
wave: 3
depends_on: ["08-02"]
files_modified:
  - src/data_architect/generation/conflict.py
  - src/data_architect/generation/dml.py
  - src/data_architect/generation/ddl.py
  - src/data_architect/generation/__init__.py
  - tests/test_conflict.py
  - tests/test_dml.py
autonomous: true

must_haves:
  truths:
    - "resolve_staging_order() sorts staging mappings by explicit priority (lower wins) then alphabetical system name"
    - "Multiple staging tables feeding the same anchor each produce a separate MERGE statement"
    - "MERGE statements are generated in priority order (highest priority source first)"
    - "Each staging source embeds its own system/tenant in the keyset identity column"
    - "Deterministic output: same spec with multiple sources produces byte-identical SQL on every run"
    - "DDL generates separate staging tables for each source mapping"
  artifacts:
    - path: "src/data_architect/generation/conflict.py"
      provides: "resolve_staging_order() deterministic conflict resolution"
      contains: "resolve_staging_order"
    - path: "tests/test_conflict.py"
      provides: "Tests for deterministic ordering, priority tie-breaking, and multi-source scenarios"
  key_links:
    - from: "src/data_architect/generation/dml.py"
      to: "src/data_architect/generation/conflict.py"
      via: "import resolve_staging_order for multi-source MERGE generation"
      pattern: "from data_architect\\.generation\\.conflict import"
    - from: "src/data_architect/generation/dml.py"
      to: "src/data_architect/generation/keyset_sql.py"
      via: "build_keyset_expr with per-source system/tenant"
      pattern: "build_keyset_expr"
---

<objective>
Multi-source conflict resolution with deterministic staging ordering and per-source MERGE generation

Purpose: When multiple staging tables feed the same anchor (e.g., Customer from Northwind and SAP), generate correct loading SQL for each source with explicit priority ordering and provenance tracking via keyset identity (STG-05). This completes the Phase 8 multi-source data loading capability.

Output: Conflict resolution module with deterministic ordering, updated DML generator producing per-source MERGE statements, and updated DDL generating staging tables for all sources.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-keyset-identity-and-staging-mappings/08-RESEARCH.md
@.planning/phases/08-keyset-identity-and-staging-mappings/08-01-SUMMARY.md
@.planning/phases/08-keyset-identity-and-staging-mappings/08-02-SUMMARY.md
@src/data_architect/generation/dml.py
@src/data_architect/generation/ddl.py
@src/data_architect/generation/keyset_sql.py
@src/data_architect/models/staging.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Conflict resolution module and multi-source MERGE generation</name>
  <files>
    src/data_architect/generation/conflict.py
    src/data_architect/generation/dml.py
    src/data_architect/generation/ddl.py
    src/data_architect/generation/__init__.py
    tests/test_conflict.py
    tests/test_dml.py
  </files>
  <action>
    **1. Create src/data_architect/generation/conflict.py:**

    ```python
    def resolve_staging_order(mappings: list[StagingMapping]) -> list[StagingMapping]:
        """Sort staging mappings deterministically for conflict resolution.

        Ordering:
        1. Explicit priority (lower number wins). None treated as lowest priority (999999).
        2. Alphabetical by system name (deterministic tie-breaker).
        3. Alphabetical by tenant name (further tie-breaker).

        Returns: Sorted list (highest priority first = lowest number first)
        """
        def sort_key(m: StagingMapping) -> tuple[int, str, str]:
            priority = m.priority if m.priority is not None else 999999
            return (priority, m.system, m.tenant)
        return sorted(mappings, key=sort_key)
    ```

    Pure function, no side effects, deterministic output. Import StagingMapping from data_architect.models.staging.

    **2. Update src/data_architect/generation/dml.py:**

    Modify `build_anchor_merge()` to handle multi-source:
    - When `anchor.staging_mappings` has MULTIPLE entries, generate one MERGE per source
    - Use resolve_staging_order() to determine iteration order
    - Each MERGE uses its own source table and keyset (system/tenant from that mapping)
    - Return type for multi-source: produce multiple SQL strings

    Modify `generate_all_dml()` to handle multi-source anchors:
    - When anchor has multiple staging_mappings, call resolve_staging_order()
    - Generate one MERGE per source, naming output files with source suffix:
      e.g., `AC_Customer_load_northwind.sql`, `AC_Customer_load_sap.sql`
    - For single-source anchors (0 or 1 mapping), behavior unchanged

    Similarly update `build_attribute_merge()` for multi-source:
    - Each source mapping may provide different column_mappings
    - Generate one attribute MERGE per source with its column lineage

    **3. Update src/data_architect/generation/ddl.py:**

    In `generate_all_ddl()`, the current logic already iterates staging_mappings.
    Verify it generates a separate staging table DDL for each StagingMapping (each source has its own staging table). If an anchor has 2 staging_mappings with different table names, both get DDL files.

    **4. Update src/data_architect/generation/__init__.py:**
    - Export resolve_staging_order from conflict module

    **5. Create tests/test_conflict.py:**

    Test cases:
    - Single mapping: returns as-is
    - Two mappings, both with priority: lower number first
    - Two mappings, one with None priority: the one with explicit priority comes first
    - Two mappings, same priority: alphabetical by system name
    - Three mappings, mixed: priority first, then system name
    - Determinism: calling twice returns identical order

    **6. Update tests/test_dml.py:**

    Add multi-source test scenarios:
    - Anchor with 2 staging_mappings generates 2 MERGE statements
    - File naming includes source system suffix
    - Each MERGE uses correct system/tenant in keyset
    - Priority ordering is reflected in output
    - Single-source anchor behavior unchanged (no regression)

    **CRITICAL: Determinism test:**
    Generate DML for a multi-source anchor twice. Assert byte-identical output. This verifies GEN-08 deterministic generation with conflict resolution.
  </action>
  <verify>
    ```bash
    python -m pytest tests/test_conflict.py tests/test_dml.py -v
    make check

    # Determinism verification
    python -c "
    from data_architect.generation.conflict import resolve_staging_order
    from data_architect.models.staging import StagingMapping, StagingColumn
    mappings = [
        StagingMapping(system='SAP', tenant='EU', table='stg_sap', natural_key_columns=['id'], columns=[], column_mappings={}),
        StagingMapping(system='Northwind', tenant='US', table='stg_nw', natural_key_columns=['id'], columns=[], column_mappings={}, priority=1),
    ]
    result = resolve_staging_order(mappings)
    assert result[0].system == 'Northwind', 'Priority 1 should come first'
    assert result[1].system == 'SAP', 'None priority should come last'
    print('Conflict resolution: PASS')
    "
    ```
  </verify>
  <done>
    resolve_staging_order deterministically sorts by priority then system name. Multi-source anchors produce one MERGE per source with correct keyset identity. DDL generates staging tables for all sources. Output is deterministic (byte-identical across runs). All tests pass including multi-source scenarios. make check green.
  </done>
</task>

</tasks>

<verification>
```bash
# Full test suite
make check

# Verify conflict module
python -c "from data_architect.generation.conflict import resolve_staging_order; print('OK')"

# Verify deterministic multi-source DML
python -c "
from data_architect.models.staging import StagingMapping, StagingColumn
from data_architect.models.anchor import Anchor
from data_architect.generation.dml import generate_all_dml
from data_architect.models.spec import Spec

# Create anchor with 2 sources
anchor = Anchor(
    mnemonic='CU',
    descriptor='Customer',
    identity='bigint',
    staging_mappings=[
        StagingMapping(system='Northwind', tenant='US', table='stg_nw_customers', natural_key_columns=['CustomerID'], columns=[StagingColumn(name='CustomerID', type='varchar(10)')], column_mappings={}, priority=1),
        StagingMapping(system='SAP', tenant='EU', table='stg_sap_customers', natural_key_columns=['KUNNR'], columns=[StagingColumn(name='KUNNR', type='varchar(10)')], column_mappings={}, priority=2),
    ],
)
spec = Spec(anchors=[anchor])

# Generate twice and compare
dml1 = generate_all_dml(spec, 'postgres')
dml2 = generate_all_dml(spec, 'postgres')
assert dml1 == dml2, 'Deterministic output failed'
print(f'Generated {len(dml1)} DML files deterministically')
"
```
</verification>

<success_criteria>
- resolve_staging_order exported from data_architect.generation.conflict
- Multi-source anchors produce N MERGE statements (one per source)
- MERGE statements ordered by priority (lower wins) then alphabetical system name
- Each MERGE embeds source-specific system/tenant in keyset identity
- DDL generates all staging tables for all sources
- File naming distinguishes multi-source files (system suffix)
- Single-source behavior unchanged (no regression)
- Deterministic output verified (byte-identical across runs)
- All tests pass including multi-source and conflict resolution
- make check passes
</success_criteria>

<output>
After completion, create `.planning/phases/08-keyset-identity-and-staging-mappings/08-03-SUMMARY.md`
</output>

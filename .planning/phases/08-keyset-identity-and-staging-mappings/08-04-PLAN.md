---
phase: 08-keyset-identity-and-staging-mappings
plan: 04
type: execute
wave: 1
depends_on: []
files_modified:
  - src/data_architect/generation/dml.py
  - tests/test_dml.py
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Generated DML uses keyset identity column constructed from staging source natural key columns instead of hardcoded 'architect-generated'"
    - "Each staging source embeds its own system/tenant in the keyset identity column"
    - "Column-level staging mappings produce correct INSERT...SELECT with explicit column lineage from mapping.column_mappings"
    - "Composite natural keys (multi-column) produce NULL-safe concatenation with ':' separator in keyset"
    - "When no mapping is provided, DML falls back to 'architect-generated' for backward compatibility"
  artifacts:
    - path: "src/data_architect/generation/dml.py"
      provides: "Keyset identity integration and column mapping usage in MERGE builders"
      contains: "build_keyset_expr"
    - path: "tests/test_dml.py"
      provides: "Tests verifying keyset presence and column mapping in generated SQL"
      contains: "keyset"
  key_links:
    - from: "src/data_architect/generation/dml.py"
      to: "src/data_architect/generation/keyset_sql.py"
      via: "import build_keyset_expr, build_composite_natural_key_expr"
      pattern: "from data_architect\\.generation\\.keyset_sql import"
    - from: "dml.py build_anchor_merge"
      to: "keyset_sql.py build_keyset_expr"
      via: "function call when mapping is provided"
      pattern: "build_keyset_expr\\("
    - from: "dml.py build_attribute_merge"
      to: "mapping.column_mappings"
      via: "dict lookup for staging column name"
      pattern: "column_mappings"
---

<objective>
Wire keyset identity SQL builder and column mappings into DML generation, closing the two critical gaps found during Phase 8 verification.

Purpose: Phase 8's core goal is "generate loading SQL that tracks data provenance." The keyset SQL builder exists and is tested, but it is NOT integrated into dml.py. Column mappings exist in the model but are NOT used in DML SELECT clauses. These two wiring gaps prevent KEY-03, STG-01, and STG-04 from being satisfied.

Output: Updated dml.py with keyset identity in MERGE statements and column mapping usage in attribute SELECT clauses, plus tests proving both integrations work.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-keyset-identity-and-staging-mappings/08-02-SUMMARY.md
@.planning/phases/08-keyset-identity-and-staging-mappings/08-03-SUMMARY.md
@.planning/phases/08-keyset-identity-and-staging-mappings/08-VERIFICATION.md
@src/data_architect/generation/dml.py
@src/data_architect/generation/keyset_sql.py
@src/data_architect/models/staging.py
@tests/test_dml.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Integrate keyset identity into DML MERGE builders</name>
  <files>src/data_architect/generation/dml.py</files>
  <action>
    Import keyset SQL builders at top of dml.py:
    ```python
    from data_architect.generation.keyset_sql import (
        build_composite_natural_key_expr,
        build_keyset_expr,
    )
    ```

    Create a helper function `_build_metadata_id_expr()` to encapsulate the keyset-or-fallback logic:
    ```python
    def _build_metadata_id_expr(
        anchor: Anchor, mapping: StagingMapping | None, dialect: str
    ) -> str:
        """Build metadata_id expression: keyset if mapping exists, else literal fallback.

        When a staging mapping is provided, constructs a keyset identity expression
        using build_keyset_expr() with the mapping's system, tenant, and natural key columns.
        For composite natural keys (multiple columns), uses build_composite_natural_key_expr()
        to concatenate with ':' separator and NULL propagation.

        When no mapping is provided, returns the literal 'architect-generated' for
        backward compatibility.

        Returns:
            SQL expression string suitable for embedding in f-string SQL templates.
        """
    ```
    Implementation details:
    - If `mapping is None`, return `"'architect-generated'"` (the literal string)
    - If `mapping is not None`:
      1. Build composite natural key: `build_composite_natural_key_expr(mapping.natural_key_columns, dialect)`
      2. Get the SQL string from that expression: `nk_expr_sql = nk_expr.sql(dialect=dialect)`
      3. Build keyset expression: Since `build_keyset_expr` takes a column name string (not an expression), and composite keys produce a complex expression, we need to handle this. For single-column natural keys, pass the column name directly. For multi-column, we need to generate the full keyset SQL manually using the pattern from keyset_sql.py.
      4. Approach: Use `build_keyset_expr(anchor.descriptor, mapping.system, mapping.tenant, nk_column_name, dialect)` for single-column keys. For composite keys, build the keyset SQL using the same CASE WHEN pattern but with the composite expression as the natural key part.
      5. Simpler approach: Generate the keyset SQL expression using build_keyset_expr for single column, and for composite, construct the SQL inline using the pattern:
         ```
         CASE WHEN {nk_null_check} THEN NULL ELSE CONCAT('{prefix}', {escaped_nk}) END
         ```
         where the prefix and escaping come from keyset_sql.py helpers.
      6. **Recommended simplest approach:** Since dml.py uses f-string SQL templates parsed by SQLGlot, generate the metadata_id as a SQL string fragment:
         - For single natural key column: call `build_keyset_expr(anchor.descriptor, mapping.system, mapping.tenant, mapping.natural_key_columns[0], dialect)` and get `.sql(dialect=dialect)` to produce the SQL string
         - For composite natural keys (len > 1): first build composite nk expression via `build_composite_natural_key_expr(mapping.natural_key_columns, dialect)`, get its SQL, then build the full keyset using the escaped prefix and CASE WHEN pattern. Use `escape_delimiters` from `data_architect.identity.escaping` for prefix escaping, and wrap with: `CASE WHEN {composite_nk_sql} IS NULL THEN NULL ELSE CONCAT('{prefix}', REPLACE(REPLACE(REPLACE(CAST({composite_nk_sql} AS VARCHAR), '@', '@@'), '~', '~~'), '|', '||')) END`
      7. Return the SQL expression string (without `AS metadata_id` alias -- the caller adds that)

    Replace all hardcoded `'architect-generated'` occurrences in dml.py:

    **In `build_anchor_merge()`** (lines ~62, ~83):
    - Call `metadata_id_sql = _build_metadata_id_expr(anchor, mapping, dialect)`
    - In postgres template: replace `'architect-generated' AS metadata_id` with `{metadata_id_sql} AS metadata_id`
    - In tsql/snowflake template: replace `'architect-generated'` in VALUES with `{metadata_id_sql}`

    **In `build_attribute_merge()`** (lines ~150, ~177, ~196, ~202, ~214, ~228):
    - Call `metadata_id_sql = _build_metadata_id_expr(anchor, mapping, dialect)`
    - Replace all `'architect-generated'` with `{metadata_id_sql}` in both historized and static branches, both postgres and tsql/snowflake templates
    - Note: The static postgres ON CONFLICT DO UPDATE SET also has `metadata_id = 'architect-generated'` -- replace with `metadata_id = {metadata_id_sql}`

    **Leave `build_knot_merge()` and `build_tie_merge()` unchanged** -- knots and ties don't have staging mappings or keyset identity (they use the literal 'architect-generated' correctly).

    Also add the import for escape_delimiters:
    ```python
    from data_architect.identity.escaping import escape_delimiters
    ```
  </action>
  <verify>
    Run `python -c "from data_architect.generation.dml import build_anchor_merge; from data_architect.models.anchor import Anchor; from data_architect.models.staging import StagingMapping, StagingColumn; mapping = StagingMapping(system='Northwind', tenant='ACME', table='stg_c', natural_key_columns=['CustomerID'], columns=[StagingColumn(name='CustomerID', type='varchar(10)')]); anchor = Anchor(mnemonic='CU', descriptor='Customer', identity='bigint', staging_mappings=[mapping]); sql = build_anchor_merge(anchor, 'postgres', mapping).sql(dialect='postgres'); print('Has keyset:', 'Customer@Northwind~ACME' in sql); print('Has hardcoded:', 'architect-generated' in sql)"` -- should print "Has keyset: True, Has hardcoded: False"

    Run `python -c "from data_architect.generation.dml import build_anchor_merge; from data_architect.models.anchor import Anchor; anchor = Anchor(mnemonic='CU', descriptor='Customer', identity='bigint'); sql = build_anchor_merge(anchor, 'postgres').sql(dialect='postgres'); print('Has fallback:', 'architect-generated' in sql)"` -- should print "Has fallback: True" (backward compatibility)

    Run `pytest tests/test_dml.py -x` -- all existing tests must still pass
  </verify>
  <done>
    - build_keyset_expr is imported and called in dml.py when a mapping is provided
    - All 4 hardcoded 'architect-generated' occurrences in build_anchor_merge and build_attribute_merge are replaced with keyset expressions when mapping is available
    - build_knot_merge and build_tie_merge unchanged (still use literal)
    - Backward compatibility: when no mapping is provided, 'architect-generated' is still used
    - All existing tests pass
  </done>
</task>

<task type="auto">
  <name>Task 2: Use column_mappings in attribute DML SELECT and add keyset/mapping tests</name>
  <files>src/data_architect/generation/dml.py, tests/test_dml.py</files>
  <action>
    **Part A: Column mapping integration in build_attribute_merge()**

    In `build_attribute_merge()`, update the value column reference in the SELECT clause to use `mapping.column_mappings` when available:

    1. After determining `value_col` (the target attribute column name), check if the mapping provides a column mapping for this attribute's mnemonic:
       ```python
       # Determine staging source column name
       if mapping and mapping.column_mappings and attribute.mnemonic in mapping.column_mappings:
           staging_value_col = mapping.column_mappings[attribute.mnemonic]
       else:
           staging_value_col = value_col  # Default: same name as target
       ```

    2. In the SELECT clause of each SQL template, use `staging_value_col` for the source column and alias it as `value_col`:
       - Postgres historized: `{staging_value_col} AS {value_col}` in SELECT (instead of just `{value_col}`)
       - Postgres static: same pattern
       - TSQL/Snowflake historized: `source.{staging_value_col}` in VALUES mapped to `{value_col}` in INSERT columns
       - TSQL/Snowflake static: same pattern

    3. **Important:** When staging_value_col == value_col (no mapping or mapping matches), the SQL remains functionally identical (just adds a self-alias which is harmless). When different, it provides the explicit column lineage (STG-01).

    **Part B: Add tests for keyset integration**

    Add the following tests to tests/test_dml.py:

    ```python
    def test_build_anchor_merge_with_mapping_has_keyset():
        """When mapping provided, metadata_id uses keyset identity (not 'architect-generated')."""
        # Create anchor with staging mapping
        # Assert 'Customer@Northwind~ACME' prefix appears in SQL
        # Assert 'architect-generated' does NOT appear in SQL
        # Assert 'CASE WHEN' appears (NULL safety)
        # Assert 'REPLACE' appears (delimiter escaping)

    def test_build_anchor_merge_without_mapping_has_fallback():
        """When no mapping, metadata_id uses 'architect-generated' literal."""
        # Create anchor without staging_mappings
        # Assert 'architect-generated' appears in SQL

    def test_build_attribute_merge_with_mapping_has_keyset():
        """Attribute MERGE uses keyset identity when mapping is provided."""
        # Create anchor with staging mapping and attribute
        # Assert keyset prefix appears in SQL

    def test_build_attribute_merge_column_mapping_used():
        """When column_mappings provided, SELECT uses mapped staging column name."""
        # Create mapping with column_mappings={"FN": "first_name_source"}
        # Generate attribute MERGE for attribute mnemonic="FN"
        # Assert 'first_name_source' appears in SQL (mapped column)

    def test_build_attribute_merge_column_mapping_fallback():
        """When no column_mappings, SELECT uses default column name."""
        # Create mapping with column_mappings={}
        # Generate attribute MERGE
        # Assert default value column name used

    def test_build_anchor_merge_composite_natural_key():
        """Composite natural key (multi-column) produces NULL-safe keyset."""
        # Create mapping with natural_key_columns=["col1", "col2"]
        # Assert keyset prefix appears
        # Assert CONCAT or ':' separator appears (composite key)

    def test_generate_all_dml_multi_source_has_keyset():
        """Full integration: multi-source spec generates DML with keyset identity per source."""
        # Create spec with 2 sources (Northwind, SAP)
        # Generate all DML
        # Assert Northwind DML has 'Customer@Northwind' keyset prefix
        # Assert SAP DML has 'Customer@SAP' keyset prefix
        # Assert neither has 'architect-generated'
    ```

    Run full test suite to verify all pass.
  </action>
  <verify>
    Run `pytest tests/test_dml.py -v` -- all tests (existing + new) must pass.

    Run `pytest tests/ -x --timeout=60` -- full test suite must pass (no regressions).

    Run `python -c "from data_architect.generation.dml import build_attribute_merge; from data_architect.models.anchor import Anchor, Attribute; from data_architect.models.staging import StagingMapping, StagingColumn; mapping = StagingMapping(system='NW', tenant='US', table='stg', natural_key_columns=['id'], columns=[StagingColumn(name='id', type='varchar(10)')], column_mappings={'FN': 'first_name_src'}); anchor = Anchor(mnemonic='CU', descriptor='Customer', identity='bigint', staging_mappings=[mapping]); attr = Attribute(mnemonic='FN', descriptor='FirstName', data_range='VARCHAR(100)'); sql = build_attribute_merge(anchor, attr, 'postgres', mapping).sql(dialect='postgres'); print('Has mapped col:', 'first_name_src' in sql)"` -- should print "Has mapped col: True"
  </verify>
  <done>
    - build_attribute_merge() uses mapping.column_mappings to look up staging column name when available
    - Falls back to default naming when no column_mappings or attribute mnemonic not in mappings
    - 7+ new tests verify keyset presence, column mapping usage, composite keys, and fallback behavior
    - All existing tests still pass (no regression)
    - Full test suite passes
  </done>
</task>

</tasks>

<verification>
Gap closure verification (re-check the 3 failed/partial truths from 08-VERIFICATION.md):

1. **Truth #10 (FAILED -> should be VERIFIED):** "Generated DML uses keyset identity column constructed from staging source natural key columns"
   - Verify: `grep -n "build_keyset_expr" src/data_architect/generation/dml.py` returns matches
   - Verify: Generated SQL for anchor with mapping contains `Customer@Northwind~ACME` prefix

2. **Truth #12 (PARTIAL -> should be VERIFIED):** "Column-level staging mappings produce correct INSERT...SELECT with explicit column lineage"
   - Verify: `grep -n "column_mappings" src/data_architect/generation/dml.py` returns matches in build_attribute_merge
   - Verify: Generated SQL uses mapped column name when column_mappings provided

3. **Truth #16 (FAILED -> should be VERIFIED):** "Each staging source embeds its own system/tenant in the keyset identity column"
   - Verify: Multi-source DML generates different keyset prefixes per source

4. **Requirements unblocked:**
   - KEY-03: build_keyset_expr called in DML generation
   - STG-01: column_mappings used in SELECT clause
   - STG-04: staging-to-anchor loading includes keyset construction

5. **Anti-patterns resolved:**
   - No more hardcoded 'architect-generated' in build_anchor_merge or build_attribute_merge when mapping provided
   - build_keyset_expr imported and used (no longer orphaned)
   - column_mappings used in SELECT clause
</verification>

<success_criteria>
- `pytest tests/test_dml.py -v` passes with 30+ tests (24 existing + 7+ new)
- `pytest tests/ -x` full suite passes with no regressions
- `grep "'architect-generated'" src/data_architect/generation/dml.py` only appears in knot/tie builders and in the fallback path (not in anchor/attribute builders when mapping is provided)
- `grep "build_keyset_expr" src/data_architect/generation/dml.py` returns at least 2 matches (import + usage)
- `grep "column_mappings" src/data_architect/generation/dml.py` returns at least 1 match in build_attribute_merge
</success_criteria>

<output>
After completion, create `.planning/phases/08-keyset-identity-and-staging-mappings/08-04-SUMMARY.md`
</output>

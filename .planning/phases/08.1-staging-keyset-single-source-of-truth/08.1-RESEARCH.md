# Phase 08.1: Staging keyset single source of truth - Research

**Researched:** 2026-02-10
**Domain:** SQL computed/generated columns, SQLGlot AST generation, keyset identity materialization
**Confidence:** HIGH

## Summary

Phase 08.1 addresses a code quality and maintainability issue identified during Phase 8 verification: keyset identity expressions are currently computed inline in every DML MERGE statement, resulting in complex, repetitive SQL expressions (148-319 characters per occurrence). Moving this computation to a single materialized column in staging table DDL eliminates duplication, simplifies DML statements, and creates a single source of truth.

The solution leverages **database-native generated/computed columns** with dialect-specific syntax, using SQLGlot's `ComputedColumnConstraint` to generate portable DDL. This approach is database-optimized (stored columns are indexed/queryable), maintains NULL safety guarantees, and requires minimal changes to existing code patterns.

**Primary recommendation:** Add a `keyset_id VARCHAR(500) GENERATED ALWAYS AS (...) STORED` column to staging table DDL, then reference `source.keyset_id` in downstream MERGE statements instead of recomputing the expression inline.

## Standard Stack

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| SQLGlot | 25.29.0+ | SQL AST generation, dialect transpilation | Already used for all DDL/DML generation (Phase 7), has native `ComputedColumnConstraint` support |
| PostgreSQL 12+ | N/A | Generated columns (STORED) | Project targets PostgreSQL, feature available since v12 (2019) |
| SQL Server 2008+ | N/A | Computed columns (PERSISTED) | PERSISTED keyword standard since SQL Server 2008 |
| Snowflake | N/A | Virtual columns | Computed columns supported via AS syntax |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| Existing keyset_sql.py | Current | Keyset expression builders | Reused for generated column expression (no changes needed) |
| Existing columns.py | Current | Column definition builders | Extended with new `build_keyset_column()` function |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| Generated columns | Views with keyset computation | Views would require JOINs in DML, defeating single-source-of-truth goal |
| Generated columns | Application-side computation | Breaks SQL-centric architecture, adds deployment complexity |
| STORED columns | VIRTUAL/non-persisted | Recomputes on every read, defeats performance benefit (only PostgreSQL 18+ has virtual) |

**Installation:**
```bash
# No new dependencies - uses existing SQLGlot and keyset_sql.py
```

## Architecture Patterns

### Recommended Project Structure
Current structure is unchanged:
```
src/data_architect/generation/
├── ddl.py               # Extend build_staging_table() to add keyset column
├── dml.py               # Simplify _build_metadata_id_expr() to reference column
├── columns.py           # NEW: build_keyset_column() helper
├── keyset_sql.py        # Reuse build_keyset_expr() (no changes)
└── naming.py            # Unchanged
```

### Pattern 1: Generated Column in DDL (Single Source of Truth)
**What:** Add computed column to staging table that materializes keyset identity once at load time
**When to use:** Always, when staging mapping has natural_key_columns defined
**Example:**
```python
# Source: SQLGlot ComputedColumnConstraint pattern
from data_architect.generation.keyset_sql import build_keyset_expr
import sqlglot.expressions as sge

def build_keyset_column(mapping: StagingMapping, dialect: str) -> sge.ColumnDef:
    """Build keyset_id computed column for staging table.

    Generates: keyset_id VARCHAR(500) GENERATED ALWAYS AS (...) STORED
    """
    # Reuse existing keyset expression builder
    if len(mapping.natural_key_columns) == 1:
        keyset_expr = build_keyset_expr(
            entity="<anchor.descriptor>",  # Passed from build_staging_table
            system=mapping.system,
            tenant=mapping.tenant,
            natural_key_col=mapping.natural_key_columns[0],
            dialect=dialect
        )
    else:
        # Composite key handling (existing pattern from dml.py)
        # ... composite_nk_expr + manual keyset construction
        pass

    return sge.ColumnDef(
        this=sg.to_identifier("keyset_id"),
        kind=sge.DataType.build("VARCHAR(500)", dialect=dialect),
        constraints=[
            sge.ColumnConstraint(
                kind=sge.ComputedColumnConstraint(
                    this=keyset_expr,
                    persisted=True  # STORED in PostgreSQL, PERSISTED in SQL Server
                )
            )
        ]
    )
```

**Generated SQL (PostgreSQL):**
```sql
CREATE TABLE IF NOT EXISTS stg_customers (
  CustomerID VARCHAR(10),
  CompanyName VARCHAR(100),
  keyset_id VARCHAR(500) GENERATED ALWAYS AS (
    CASE WHEN CustomerID IS NULL THEN NULL
    ELSE 'Customer@Northwind~ACME|' || REPLACE(REPLACE(REPLACE(CustomerID, '@', '@@'), '~', '~~'), '|', '||')
    END
  ) STORED,
  metadata_recorded_at TIMESTAMPTZ NOT NULL,
  metadata_recorded_by VARCHAR(255),
  metadata_id VARCHAR(255)
)
```

### Pattern 2: Reference Column in DML (Simplified MERGE)
**What:** Replace inline keyset computation with simple column reference
**When to use:** All anchor/attribute MERGE statements when mapping provided
**Example:**
```python
# BEFORE (Phase 8): 148-319 character inline expression
metadata_id_sql = _build_metadata_id_expr(anchor, mapping, dialect)
# Returns: "CASE WHEN CustomerID IS NULL THEN NULL ELSE 'Customer@...' || REPLACE(...) END"

# AFTER (Phase 08.1): Simple column reference
metadata_id_sql = "source.keyset_id" if mapping else "'architect-generated'"
```

**Generated SQL (PostgreSQL):**
```sql
-- BEFORE: Inline computation (148 chars)
INSERT INTO CU_Customer (CU_ID, metadata_recorded_at, metadata_recorded_by, metadata_id)
SELECT CU_ID, CURRENT_TIMESTAMP, 'architect',
  CASE WHEN CustomerID IS NULL THEN NULL ELSE 'Customer@Northwind~ACME|' || REPLACE(REPLACE(REPLACE(CustomerID, '@', '@@'), '~', '~~'), '|', '||') END
FROM stg_customers
ON CONFLICT (CU_ID) DO NOTHING;

-- AFTER: Column reference (clean, simple)
INSERT INTO CU_Customer (CU_ID, metadata_recorded_at, metadata_recorded_by, metadata_id)
SELECT CU_ID, CURRENT_TIMESTAMP, 'architect', source.keyset_id
FROM stg_customers AS source
ON CONFLICT (CU_ID) DO NOTHING;
```

### Pattern 3: Anchor Context Passing (New Requirement)
**What:** Staging DDL needs anchor descriptor for keyset entity field
**When to use:** When building staging table from StagingMapping
**Current challenge:** `build_staging_table(name, columns, dialect)` doesn't know anchor context
**Solution:**
```python
# Option A: Pass anchor to build_staging_table
def build_staging_table(
    name: str,
    columns: list[tuple[str, str]],
    dialect: str,
    anchor: Anchor | None = None,  # NEW
    mapping: StagingMapping | None = None  # NEW
) -> sge.Create:
    column_defs = [...]

    # Add keyset column if mapping provided
    if mapping and anchor:
        column_defs.append(build_keyset_column(anchor, mapping, dialect))

    # Existing metadata columns
    column_defs.extend(build_metadata_columns(dialect))
    return sge.Create(...)

# Option B: Add entity field to StagingMapping model
class StagingMapping(BaseModel):
    entity: str  # NEW - anchor descriptor for keyset
    system: str
    tenant: str
    # ...
```

**Recommendation:** Option A (pass anchor) preserves model purity; StagingMapping shouldn't know its parent anchor.

### Anti-Patterns to Avoid
- **Recomputing keyset in DML:** Phase 08.1's entire purpose is eliminating this
- **Virtual/non-persisted columns:** Only PostgreSQL 18+ supports virtual generated columns; use STORED for compatibility
- **Adding keyset to vault tables:** Keyset is staging-only; vault tables already have metadata_id populated from staging
- **Changing keyset expression:** Must remain identical to Phase 8 implementation (same escape sequences, NULL safety)

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Dialect-specific computed column syntax | Manual string templates per dialect | SQLGlot `ComputedColumnConstraint` | Handles `GENERATED ALWAYS AS ... STORED` (PostgreSQL), `AS ... PERSISTED` (SQL Server), `AS ...` (Snowflake) |
| Keyset expression construction | Rebuild keyset logic | Existing `build_keyset_expr()` from keyset_sql.py | Already handles delimiter escaping, NULL safety, composite keys |
| Column ordering in DDL | Manual list manipulation | Append after user columns, before metadata | Staging columns already have established pattern |

**Key insight:** SQLGlot's `ComputedColumnConstraint` with `persisted=True` automatically generates correct syntax for all dialects. PostgreSQL uses `GENERATED ALWAYS AS (...) STORED`, SQL Server uses `AS (...) PERSISTED`, Snowflake uses `AS (...)`.

## Common Pitfalls

### Pitfall 1: Forgetting Anchor Context in DDL Generation
**What goes wrong:** `generate_all_ddl()` iterates `anchor.staging_mappings` but doesn't pass anchor to `build_staging_table()`
**Why it happens:** Current signature is `build_staging_table(name: str, columns: list, dialect: str)` — no anchor parameter
**How to avoid:** Modify `generate_all_ddl()` staging section to pass anchor:
```python
for anchor in spec.anchors:
    if anchor.staging_mappings:
        for mapping in anchor.staging_mappings:
            table = staging_table_name(mapping)
            columns = [(col.name, col.type) for col in mapping.columns]
            ast = build_staging_table(table, columns, dialect, anchor, mapping)  # Pass anchor + mapping
```
**Warning signs:** `build_keyset_column()` called without anchor.descriptor raises AttributeError

### Pitfall 2: SQLGlot Expression vs String Mixing
**What goes wrong:** Passing SQLGlot `sge.Expression` to `ComputedColumnConstraint.this` but DML uses `.sql(dialect)` string
**Why it happens:** `build_keyset_expr()` returns `sge.Expression`, `ComputedColumnConstraint` expects `sge.Expression`, but type confusion possible
**How to avoid:** Always pass Expression objects to ComputedColumnConstraint, never pre-rendered SQL strings
```python
# CORRECT
keyset_expr = build_keyset_expr(...)  # Returns sge.Expression
sge.ComputedColumnConstraint(this=keyset_expr, persisted=True)

# WRONG
keyset_sql = build_keyset_expr(...).sql(dialect="postgres")  # String
sge.ComputedColumnConstraint(this=keyset_sql, persisted=True)  # Type error
```
**Warning signs:** SQLGlot raises `AttributeError: 'str' object has no attribute 'sql'`

### Pitfall 3: NULL Propagation Verification
**What goes wrong:** Assuming generated column NULL safety matches inline expression without testing
**Why it happens:** Computed columns evaluate expression at INSERT time; different evaluation context than inline SELECT
**How to avoid:** Write test verifying `INSERT INTO stg (natural_key) VALUES (NULL)` produces `keyset_id = NULL`
**Warning signs:** Tests with NULL natural keys fail; `metadata_id` populated when it should be NULL

### Pitfall 4: Column Name Collision
**What goes wrong:** User defines staging column named `keyset_id`, conflicts with generated column
**Why it happens:** `keyset_id` is a reasonable user-chosen name for natural key columns
**How to avoid:** Use reserved naming convention `_keyset_id` or check for collision before adding
**Warning signs:** DDL generation fails with "duplicate column name"

### Pitfall 5: Composite Key Mismatch
**What goes wrong:** Single-column keyset logic applied to composite key mapping
**Why it happens:** `build_keyset_expr()` expects single column name, composite keys need `build_composite_natural_key_expr()` first
**How to avoid:** Replicate dml.py `_build_metadata_id_expr()` composite key handling in new `build_keyset_column()`
**Warning signs:** Generated DDL references non-existent `composite_key` column

## Code Examples

Verified patterns from current codebase and database documentation:

### SQLGlot Generated Column Construction
```python
# Source: SQLGlot expressions.py ComputedColumnConstraint
import sqlglot as sg
import sqlglot.expressions as sge

col = sge.ColumnDef(
    this=sg.to_identifier("keyset_id"),
    kind=sge.DataType.build("VARCHAR(500)"),
    constraints=[
        sge.ColumnConstraint(
            kind=sge.ComputedColumnConstraint(
                this=sge.Concat(expressions=[
                    sge.Literal.string("prefix"),
                    sg.to_identifier("natural_key")
                ]),
                persisted=True
            )
        )
    ]
)

# Generates (PostgreSQL):
# keyset_id VARCHAR(500) GENERATED ALWAYS AS ('prefix' || natural_key) STORED

# Generates (SQL Server):
# keyset_id VARCHAR(500) AS ('prefix' + natural_key) PERSISTED

# Generates (Snowflake):
# keyset_id VARCHAR(500) AS ('prefix' || natural_key)
```

### Reusing Existing Keyset Expression
```python
# Source: Existing keyset_sql.py + new build_keyset_column()
from data_architect.generation.keyset_sql import build_keyset_expr
from data_architect.models.anchor import Anchor
from data_architect.models.staging import StagingMapping

def build_keyset_column(
    anchor: Anchor,
    mapping: StagingMapping,
    dialect: str
) -> sge.ColumnDef:
    """Build keyset_id computed column definition."""
    # Single natural key column
    if len(mapping.natural_key_columns) == 1:
        keyset_expr = build_keyset_expr(
            entity=anchor.descriptor,
            system=mapping.system,
            tenant=mapping.tenant,
            natural_key_col=mapping.natural_key_columns[0],
            dialect=dialect
        )
    else:
        # Composite key (replicate dml.py logic)
        composite_nk_expr = build_composite_natural_key_expr(
            mapping.natural_key_columns, dialect
        )
        # ... manual keyset construction with prefix + escaping
        # (see dml.py _build_metadata_id_expr lines 64-92)
        pass

    return sge.ColumnDef(
        this=sg.to_identifier("keyset_id"),
        kind=sge.DataType.build("VARCHAR(500)", dialect=dialect),
        constraints=[
            sge.ColumnConstraint(
                kind=sge.ComputedColumnConstraint(
                    this=keyset_expr,
                    persisted=True
                )
            )
        ]
    )
```

### Simplified DML Reference
```python
# Source: Modified dml.py _build_metadata_id_expr()
def _build_metadata_id_expr(
    anchor: Anchor, mapping: StagingMapping | None, dialect: str
) -> str:
    """Build metadata_id expression: keyset column reference or fallback."""
    if mapping is None:
        return "'architect-generated'"

    # Phase 08.1: Reference staging keyset_id column instead of inline computation
    return "source.keyset_id"
```

### Integration into generate_all_ddl
```python
# Source: Modified ddl.py generate_all_ddl()
def generate_all_ddl(spec: Spec, dialect: str) -> dict[str, str]:
    output: dict[str, str] = {}

    # ... knots, anchors, attributes, ties (unchanged)

    # 4. Staging tables (MODIFIED)
    staging_tables: dict[str, tuple[Anchor, StagingMapping, list[tuple[str, str]]]] = {}

    for anchor in spec.anchors:
        if anchor.staging_mappings:
            for mapping in anchor.staging_mappings:
                table = staging_table_name(mapping)
                columns = [(col.name, col.type) for col in mapping.columns]
                staging_tables[table] = (anchor, mapping, columns)  # Store anchor + mapping

    # Generate staging DDL with anchor context
    for table in sorted(staging_tables.keys()):
        anchor, mapping, columns = staging_tables[table]
        ast = build_staging_table(
            table,
            columns,
            dialect,
            anchor=anchor,      # NEW
            mapping=mapping     # NEW
        )
        filename = f"{table}.sql"
        output[filename] = ast.sql(dialect=dialect, pretty=True)

    return output
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Inline keyset computation in DML | Materialized column in DDL | Phase 08.1 (2026-02-10) | 148-319 char expressions → simple column reference |
| String concatenation for computed cols | SQLGlot `ComputedColumnConstraint` | Available in current SQLGlot 25.x | Portable dialect-specific syntax |
| Virtual columns (PostgreSQL 18+) | STORED columns (PostgreSQL 12+) | PostgreSQL 18 beta (2026) | Virtual columns too new; use STORED for compatibility |

**Deprecated/outdated:**
- Manual per-dialect computed column templates: SQLGlot handles this via `ComputedColumnConstraint`
- Application-side keyset computation: Database-native computed columns more efficient

## Open Questions

1. **Column Size: VARCHAR(500) sufficient?**
   - What we know: Current keyset format `entity@system~tenant|natural_key` with escaping can be long
   - What's unclear: Maximum realistic length for entity/system/tenant/natural_key combinations
   - Recommendation: VARCHAR(500) conservative; Phase 7 uses VARCHAR(255) for metadata_id — may need increase if long composite keys common

2. **Composite Key Expression in Computed Columns**
   - What we know: `dml.py` builds composite keys with CASE + CONCAT + REPLACE nesting (319 chars)
   - What's unclear: Does SQLGlot `ComputedColumnConstraint` handle deeply nested expressions correctly in all dialects?
   - Recommendation: Test with actual composite key (MANDT + KUNNR pattern) in PostgreSQL/SQL Server/Snowflake

3. **Index on keyset_id Column?**
   - What we know: MERGE statements use `metadata_id` for lineage tracking, not JOIN conditions
   - What's unclear: Would indexing `keyset_id` in staging improve performance for multi-source deduplication?
   - Recommendation: Start without index; add if performance profiling shows need

4. **Backward Compatibility with Existing Staging Tables**
   - What we know: Phase 08.1 changes staging DDL structure
   - What's unclear: Migration path for existing databases with Phase 8 staging tables (no keyset column)
   - Recommendation: DDL is idempotent (IF NOT EXISTS); consider ALTER TABLE ADD COLUMN in migration guide

## Sources

### Primary (HIGH confidence)
- [PostgreSQL: Documentation: 18: 5.4. Generated Columns](https://www.postgresql.org/docs/current/ddl-generated-columns.html) - STORED/VIRTUAL syntax
- [SQL Server computed_column_definition (Transact-SQL)](https://learn.microsoft.com/en-us/sql/t-sql/statements/alter-table-computed-column-definition-transact-sql?view=sql-server-ver17) - PERSISTED syntax
- [Virtual Column in Snowflake — The Complete Guide](https://snowflakewiki.medium.com/virtual-column-in-snowflake-the-complete-guide-50c1a224ffd0) - Snowflake AS syntax
- SQLGlot expressions.py source (local inspection) - ComputedColumnConstraint API
- Existing codebase: `src/data_architect/generation/keyset_sql.py`, `dml.py`, `ddl.py`, `columns.py`

### Secondary (MEDIUM confidence)
- [SQLGlot GitHub - expressions.py](https://github.com/tobymao/sqlglot/blob/main/sqlglot/expressions.py) - AST node definitions
- Phase 8 verification report (`.planning/phases/08-keyset-identity-and-staging-mappings/08-VERIFICATION.md`) - Current implementation state

### Tertiary (LOW confidence)
- None - all findings verified with official docs or codebase inspection

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH - SQLGlot already in use, computed columns standard SQL feature
- Architecture: HIGH - Pattern verified with local SQLGlot testing, aligns with existing code structure
- Pitfalls: MEDIUM - Based on common SQL computed column issues and codebase analysis, not production experience

**Research date:** 2026-02-10
**Valid until:** 60 days (stable SQL features, slow-moving database standards)
